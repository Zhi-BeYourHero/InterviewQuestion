## MySQL

<!-- GFM-TOC -->

* [Mysql](#mysql)
  * [1️⃣说说Mysql的锁？](#1️⃣ 说说MySQL的锁？)
  * [2️⃣ Mysql死锁](#2️⃣ Mysql死锁)
  * [3️⃣如果只有一条select语句，它加锁吗？](#3️⃣ 如果只有一条select语句，它加锁吗？)
  * [4️⃣如果一条delete语句，如何加锁？](#4️⃣ 如果一条delete语句，如何加锁？)
  * [5️⃣主键加锁吗？](#5️⃣ 主键加锁吗？)
  * [6️⃣数据库三范式](#6️⃣ 数据库三范式)
  * ⑦ [SQL语句分析](#⑦ SQL语句分析)
  * [8️⃣ 页分裂和页合并](#8️⃣ 页分裂和页合并)
  * [⑨ 为什么一般单表的数据不建议超过两千万？](#⑨ 为什么一般单表的数据不建议超过两千万？)
  * [10 如何查找mysql中的慢查询并进行优化？即sql性能分析](#10 如何查找mysql中的慢查询并进行优化？即sql性能分析)
  * [11 MVCC](#11 MVCC)
  * [12 explain平时怎么用？你平时优先观察哪些点？](#12 explain平时怎么用？你平时优先观察哪些点？)
  * [13 MySQL是如何执行一条SQL的](#13 MySQL是如何执行一条SQL的)

<!-- GFM-TOC -->

### 1️⃣ 说说MySQL的锁？

![image-20210122105643103](https://zhipic.oss-cn-beijing.aliyuncs.com/20210122105647.png)

三种并发控制机制：悲观并发控制、乐观并发控制和多版本并发控制。悲观并发控制其实是最常见的并发控制机制，也就是锁；乐观并发控制其实也有另一个名字：乐观锁. MVCC多版本并发控制机制，可以与前两者中的任意一种机制结合使用，以提高数据库的读性能。

#### 乐观锁

**乐观锁**：在访问数据之前，默认不会有其他事务对此数据进行修改，所以先访问数据，然后再查找在此期间是否有事务修改数据。**这不是数据库自带的，需要我们自己去实现，一般基于版本或者时间戳去实现。**

具体流程是这样的：

1）创建一张表时添加一个version字段，表示是版本号，如下：

![image-20201113135126150](https://zhipic.oss-cn-beijing.aliyuncs.com/20210122105851.png)

2）修改数据的时候首先把这条数据的版本号查出来，update时判断这个版本号是否和数据库里的一致，如果一致则表明这条数据没有被其他用户修改，若不一致则表明这条数据在操作期间被其他客户修改过，此时需要在代码中抛异常或者回滚等。伪代码如下：

```mysql
update tb set name='yyy' and version=version+1 where id=1 and version=version;

1. SELECT name AS old_name, version AS old_version FROM tb where ...;

2. 根据获取的数据进行业务操作，得到new_dname和new_version

3.UPDATE SET name = new_name, version = new_version WHERE version = old_version

if(updated row > 0) {

// 乐观锁获取成功，操作完成

}else{

// 乐观锁获取失败，回滚并重试

}
```

update其实在不在事务中都无所谓，在内部是这样的：update是单线程的，即如果一个线程对一条数据进行

update操作，会获得锁，其他线程如果要对同一条数据操作会阻塞，直到这个线程update成功后释放锁。

另外，**乐观锁不需要数据库底层的支持！！！**

大概是因为一条sql的执行过程，如下所示，显然会先获取到对应的数据，去获取数据的时候是不会去获取🔒的，所以就不会先加行锁了！因为之前还想过使用update不是也用到了行锁嘛。。。

一、sql执行顺序 
(1)from 
(3) join 
(2) on 
(4) where 
(5)group by(开始使用select中的别名，后面的语句中都可以使用)
(6) avg,sum.... 
(7)having 
(8) select 
(9) distinct 
(10) order by

#### 悲观锁

正如其名字一样，悲观锁对数据加锁持有一种悲观的态度。因此，在整个数据处理过程中，将数据处于锁定状态。**悲观锁的实现，往往依靠数据库提供的锁机制**（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。

##### 按锁粒度分类

MySQL 中提供了两种封锁粒度：行级锁以及表级锁。

应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。

但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。因此**封锁粒度越小，系统开销就越大。**

在**选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡**。

- **表级锁**

  Mysql中锁定 **粒度最大** 的一种锁，对当前操作的整张表加锁，实现简单 **，资源消耗也比较少，加锁快，不会出现死锁** 。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM和 InnoDB引擎都支持表级锁。

- **行级锁**

  Mysql中锁定 **粒度最小** 的一种锁，只针对当前操作的行进行加锁。 **行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。** InnoDB支持的行级锁，包括如下几种。

  - **Record Lock:** 对索引项加锁，锁定符合条件的行。其他事务不能修改和删除加锁项；锁住某一行，如果表存在索引，那么记录锁是锁在索引上的，**如果表没有索引，那么 InnoDB 会创建一个隐藏的聚簇索引加锁**。

  - **Gap Lock:** 对索引项之间的“间隙”加锁，锁定记录的范围（对第一条记录前的间隙或最后一条将记录后的间隙加锁），不包含索引项本身。其他事务不能在锁范围内插入数据，这样就防止了别的事务新增幻影行。**间隙锁是一种记录行与记录行之间存在空隙或在第一行记录之前或最后一行记录之后产生的锁**。间隙锁可能占据的单行，多行或者是空记录。 对索引项之间的“间隙”加锁，锁定记录的范围,不包含索引项本身。**其他事务不能在锁范围内插入数据，这样就防止了别的事务新增幻影行**。

  - **Next-key Lock：** 锁定索引项本身和索引范围。即Record Lock和Gap Lock的结合。可解决幻读问题。

  - 数据库锁的是什么？
    数据引擎：Innodb
    其实数据库锁的是聚集索引

    聚集索引怎么来？
    当有主键时，主键是聚集索引
    当没有主键时，但是有唯一索引，会找第一个非空的唯一索引当成聚集索引
    当没有主键，也没有唯一索引时，其内部有一个rowid来当聚集索引

    **没有设置索引的表：当表结构没有设置索引的时候，就会锁住全表**
    有设置主键索引的表：锁住指定主键的记录
    有设置唯一索引的表：如果锁条件是根据唯一索引来进行锁操作，也是锁住该聚集索引对应的记录
    当然了，如果其条件都不存在，则有可能锁住的是间隙锁、临键锁，也就是上面所介绍的三种锁情况

    [记录锁、间隙锁、临键锁](https://blog.csdn.net/weixin_43871678/article/details/108743296)

  - **相关知识点：**

    1. innodb对于行的查询使用next-key lock
    2. Next-locking keying为了解决Phantom Problem幻读问题
    3. 当**查询的索引含有唯一属性时，将next-key lock降级为record key**
    4. Gap锁设计的目的是为了阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生
    5. 有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock） A. 将事务隔离级别设置为RC B. 将参数innodb_locks_unsafe_for_binlog设置为1

**虽然使用行级索具有粒度小、并发度高等特点，但是表级锁有时候也是非常必要的**：

- 事务更新大表中的大部分数据直接使用表级锁效率更高；
- 事务比较复杂，使用行级索很可能引起死锁导致回滚。

##### 按锁是否可写分类

**表级锁和行级锁可以进一步划分为共享锁（s）和排他锁（X）。**

- 互斥锁（Exclusive），简写为 X 锁，又称写锁。

  - ```mysql
    SELECT * FROM table_name WHERE ... FOR UPDATE;
    ```

- 共享锁（Shared），简写为 S 锁，又称读锁。

  - ```mysql
    SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE;
    ```

加锁必须先开启事务：begin;（开启事务）->加锁、操作->commit;（提交事务，归还锁）

加锁分为显式加锁与隐式加锁，上面的写法是显式加锁。mysql在执行insert、update会自动加锁，mysql对select却不会加锁。

有以下两个规定：

- 一个事务对数据对象 A 加了 X 锁，就可以对 A 进行读取和更新。加锁期间其它事务不能对 A 加任何锁。
- 一个事务对数据对象 A 加了 S 锁，可以对 A 进行读取操作，但是不能进行更新操作。加锁期间其它事务能对 A 加 S 锁，但是不能加 X 锁。

锁的兼容关系如下：

![image-20200809002326242](https://zhipic.oss-cn-beijing.aliyuncs.com/20210122110428.png)

##### 另外两个表级锁：IS和IX

​	Innodb同时支持行锁和表锁。但行锁和表锁的同时存在会发生冲突，**如A申请了行共享锁，而B再申请表互斥锁**。**这时B不仅需要查看是否已经存在其他表锁，以及逐个查看是否存在行锁，效率太低。于是又引入了意向锁**。意向锁是一种表级锁，用来指示接下来的一个事务将要获取的是什么类型的锁（共享还是独占）。意向锁分为意向共享锁（IS）和意向独占锁（IX），依次表示接下来一个事务将会获得共享锁或者独占锁。

**InnoDB另外的两个表级锁：**

- **意向共享锁（IS）：** 表示事务准备给数据行记入共享锁，事务在一个数据行加共享锁前必须先取得该表的IS锁。
- **意向排他锁（IX）：** 表示事务准备给数据行加入排他锁，事务在一个数据行加排他锁前必须先取得该表的IX锁。

在意向锁存在的情况下，事务A必须先申请表的意向共享锁，成功后再申请一行的行锁。而**事务B发现表上有意向共享锁，说明表中有些行被共享行锁锁住了，因此，事务B申请表的写锁会被阻塞**。而且，**申请意向锁的动作是数据库自动完成的，不需要我们手动申请。**

**注意：**

1. **这里的意向锁是表级锁，表示的是一种意向，仅仅表示事务正在读或写某一行记录，在真正加行锁时才会判断是否冲突。意向锁是InnoDB自动加的，不需要用户干预。**
2. **IX，IS是表级锁，不会和行级的X，S锁发生冲突，只会和表级的X，S发生冲突。**

**InnoDB的锁机制兼容情况如下：**

![image-20201113132233695](https://zhipic.oss-cn-beijing.aliyuncs.com/20210122110434.png)

**当一个事务请求的锁模式与当前的锁兼容，InnoDB就将请求的锁授予该事务；反之如果请求不兼容，则该事物就等待锁释放。**

##### 元数据锁

MDL (metaDataLock) 元数据：表结构

在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；**当要对表做结**

**构变更操作的时候，加 MDL 写锁。**

元数据锁是用来保护表结构的，避免在CRUD的时候被修改表结构  

### 2️⃣ Mysql死锁

可能因为记录🔒或者间隙锁产生死锁

#### 为什么会形成死锁

也许你会有这样的疑问，事务和谈判不一样，为什么事务不能使用完锁之后立马释放呢？居然还要操作完了之后一直持有锁？这就涉及到 MySQL 的并发控制了。

**MySQL的并发控制有两种方式，一个是 MVCC，一个是两阶段锁协议。**那么为什么要并发控制呢？是因为多个用户同时操作 MySQL 的时候，为了提高并发性能并且要求如同多个用户的请求过来之后如同串行执行的一样（`可串行化调度`）。具体的并发控制这里不再展开。咱们继续深入讨论两阶段锁协议。

##### 两阶段锁协议（2PL）

官方定义：

> 两阶段锁协议是指所有事务必须分两个阶段对数据加锁和解锁，在对任何数据进行读、写操作之前，事务首先要获得对该数据的封锁；在释放一个封锁之后，事务不再申请和获得任何其他封锁。

对应到 MySQL 上分为两个阶段：

1. 扩展阶段（事务开始后，commit 之前）：获取锁
2. 收缩阶段（commit 之后）：释放锁

![image-20200914003006090](https://zhipic.oss-cn-beijing.aliyuncs.com/20210122112232.png)

就是说呢，只有遵循两段锁协议，才能实现 `可串行化调度`。

但是**两阶段锁协议不要求事务必须一次将所有需要使用的数据加锁**，并且**在加锁阶段没有顺序要求，所以这种并发控制方式会形成死锁**。

#### 如何处理死锁

Mysql死锁处理方式

1、等待，直到超时（innodb_lock_wait_timeout=50s），事务自动回滚。

2、发起死锁检测，主动回滚一条事务，让其他事务继续执行（innodb_deadlock_detect=on）。

**由于性能原因，一般都是使用死锁检测来进行处理死锁**。

- 死锁检测
  - 死锁检测的原理是构建一个以事务为顶点、锁为边的有向图，判断有向图是否存在环，存在即有死锁。
  - 检测到死锁之后，**选择插入更新或者删除的行数最少的事务回滚**，基于 INFORMATION_SCHEMA.INNODB_TRX 表中的 trx_weight 字段来判断。

**MySQL默认会主动探知死锁，并回滚某一个影响最小的事务。等另一事务执行完成之后，再重新执行该**
**事务。**  

#### 如何避免死锁 ？

##### 收集死锁信息：

1. 利用命令 `SHOW ENGINE INNODB STATUS`查看死锁原因。
2. 调试阶段开启 innodb_print_all_deadlocks，收集所有死锁日志。

##### 减少死锁：

1. 使用事务，不使用 `lock tables` 。
2. 保证没有长事务。
3. 操作完之后立即提交事务，特别是在交互式命令行中。
4. 如果在用 `(SELECT ... FOR UPDATE or SELECT ... LOCK IN SHARE MODE)`，尝试降低隔离级别。
5. 修改多个表或者多个行的时候，`将修改的顺序保持一致`。
6. 创建索引，可以使创建的锁更少。
7. 最好不要用 `(SELECT ... FOR UPDATE or SELECT ... LOCK IN SHARE MODE)`。
8. 如果上述都无法解决问题，那么尝试使用 `lock tables t1, t2, t3` 锁多张表

##### 1、注意程序的逻辑

根本的原因是程序逻辑的顺序，最常见的是交差更新
Transaction 1: 更新表A -> 更新表B
Transaction 2: 更新表B -> 更新表A
Transaction获得两个资源  

##### 2、保持事务的轻量  

越是轻量的事务，占有越少的锁资源，这样发生死锁的几率就越小  

##### 3、提高运行的速度  

避免使用子查询，尽量使用主键等等  

##### 4、尽量快提交事务，减少持有锁的时间  

越早提交事务，锁就越早释放  

### 3️⃣ 如果只有一条select语句，它加锁吗？

​	RC,RR有MVCC，select不加锁

### 4️⃣ 如果一条delete语句，如何加锁？

​	谈锁前提  

```mysql
select * from t1 where id = 10;
delete from t1 where name = 'zs';
```

前提一：id列是不是主键？
**前提二**：当前系统的隔离级别是什么？RC,RR有MVCC，select不加锁。Serializable每个操作都加锁
前提三：id列如果不是主键，那么id列上有索引吗？  

#### 简单SQL的加锁分析  

RC隔离级别下  

##### 组合一：id主键+RC  

这个组合，是最简单，最容易分析的组合。id是主键，Read Committed隔离级别，

```mysql
delete from t1 where id = 10;
```

只需要将主键上id = 10的记录加上X锁即可。

![image-20200915091104943](https://zhipic.oss-cn-beijing.aliyuncs.com/20210122113011.png)

##### 组合二：id唯一索引+RC  

这个组合，id不是主键，而是一个Unique的二级索引键值。那么在RC隔离级别下， 需要加什么锁呢？
见下图：  

```mysql
delete from t1 where id = 10;
```

![image-20200915091332236](https://zhipic.oss-cn-beijing.aliyuncs.com/20210122113029.png)

![image-20200915091342757](https://zhipic.oss-cn-beijing.aliyuncs.com/20210122113046.png)

##### 组合三：id非唯一索引+RC  

相对于组合一、二，组合三又发生了变化，隔离级别仍旧是RC不变，但是id列上的约束又降低了，id列
不再唯一，只有一个普通的索引。假设以下语句，仍旧选择id列上的索引进行过滤where条件，那么此
时会持有哪些锁？同样见下图：  

![image-20200915091631991](https://zhipic.oss-cn-beijing.aliyuncs.com/20210122113109.png)

##### 组合四：id无索引+RC  

id列上没有索引，where id = 10;这个过滤条件，没法通过索引进行过滤，那么只能走全表扫描做过
滤。对应于这个组合，SQL会加什么锁？或者是换句话说，全表扫描时，会加什么锁？这个答案也有很
多：有人说会在表上加X锁；有人说会将聚簇索引上，选择出来的id = 10;的记录加上X锁。那么实际情
况呢？请看下图：  

![image-20200915091820821](https://zhipic.oss-cn-beijing.aliyuncs.com/20210122113143.png)

##### 组合五：id主键+RR  

同组合一
**主键等值 不产生Gap锁**
**主键范围 产生 Gap**  

##### 组合六：id唯一索引+RR 

同组合二  

##### 组合七：id非唯一索引+RR  

delete from t1 where id = 10;  

![image-20200915092051717](https://zhipic.oss-cn-beijing.aliyuncs.com/20210122113246.png)

![image-20200915092158269](https://zhipic.oss-cn-beijing.aliyuncs.com/20210122113258.png)

**不能在间隙 insert 防止幻读 （RR）**  

![image-20200915092218628](https://zhipic.oss-cn-beijing.aliyuncs.com/20210122113407.png)

##### 组合八：id无索引+RR  

![image-20200915092320735](https://zhipic.oss-cn-beijing.aliyuncs.com/20210122113429.png)

##### 组合九：Serializable （LBCC）  

只要有SQL 就锁 而且 无索引 表锁
select 是加锁的  

### 5️⃣ 主键加锁吗？

​	在RR模式下，主键一般都是加record lock，如果是范围就使用Next-key lock

### 6️⃣ 数据库三范式

范式是具有最小冗余的表结构

#### 第一范式

**1、属性的原子性**

**第一范式就是数据库中的每一列都是不可分割的最小单元。**

![image-20200807233620269](https://zhipic.oss-cn-beijing.aliyuncs.com/20210122114917.png)

#### 第二范式

**第二范式就是属性完全依赖于主键**[消除部分子函数依赖]，不满足时垂直拆分为一张新表。保证一张表只描述一件事情，即一个关系

首先是 1NF，另外包含两部分内容，一是表必须有一个主键；二是没有包含在主键中的列必须完全依赖于主键，而不能只依赖于主键的一部分。

![image-20200807234058412](https://zhipic.oss-cn-beijing.aliyuncs.com/20210122115009.png)

#### 第三范式

**第三范式（3NF）不存在对非主键列的传递依赖**：首先是 2NF，另外非主键列必须直接依赖于主键，不能存在传递依赖。即不能存在：非主键列 A 依赖于非主键列 B，非主键列 B 依赖于主键的情况。

![image-20200807234953906](https://zhipic.oss-cn-beijing.aliyuncs.com/20210122115108.png)

### ⑦ SQL语句分析

1. 一个表，a为主键，b为唯一索引，c没有索引。`select * from t where a=1`更快，还是`select * from t where b=1`更快。ps：两个查询对应同一个记录

   a更快吧，a不用回表但是b要回表，

2. `select a,b from t where a=1` 更快，还是`select a,b from t where b=1`更快

   后面一个更快吧？访问的数据更少...  直接通过索引即可。。。

3. 给了一个 sql ，delete from table where id = 8; 问 假设 repeatable read 隔离级别下并且 id 是主键，会加什么锁？答 record lock。 
   那 id 是普通索引，会加什么锁？答 next-key lock。那如果 read committed 隔离级别下并且 id 不是索引呢？答 table lock。

4. select * from user order by name limit N offset M 会查询多少行记录？如何优化，不通过增加索引。

### 8️⃣ 页分裂和页合并

数据库使用的是mysql，主键id由雪花算法生成的（19位），并且随着时间递增，这迎合了mysql索引B+树的设计，倘若主键不是随着时间递增的，会导致在插入数据的时候频繁的出现页分裂和页合并，极大的降低了数据库的性能。

页分裂和页合并

1. `在内存中，数据是按页保存的，mysql其实也可以看做为是一种文件存储系统，只不过存储的文件需要遵循一定的格式，使其在读取的时候能够快速的检索和访问，不同的存储引擎其实是不同的存储格式。`
2. `mysql每次将数据加载到内存中也是按页加载（4页），大多数操作系统1页的大小为4K，使用b+树，可以极大的减少IO的次数，加大检索的效率，3层的b+树支持千万级别数据的存储。`

### ⑨ 为什么一般单表的数据不建议超过两千万？

我们有个基础的假设，我们希望mysql层级在2-3层，尽量不超过三层，超过三层了，如果数据不在内存里，就得去数据里捞，就得多一次数据库的IO操作。这样我们就可以做一个简单的计算，假设我们的id是bigint，bigint在mysql里实际存储占8个字节，而指针大小在mysql里是6个字节，这样的话，一个主键占14个字节。一个页在mysql里默认是16k，16k/14大概是1170，也就是说一个块，一个页可以最大放下1170个主键。一颗高度为2的B+Tree，他可以有16个块，也就是可以存16 * 1170 = 18720条数据。也就是说理论上不超过18720条数据，他的B+Tree的索引树只有2层，超过了就得三层。那如果是三层可以存多少数据呢？1170 * 1170 * 16 等于2190万，也就是根据我们的索引层次结构，估算出来的理论最高值。

### 10 如何查找mysql中的慢查询并进行优化？即sql性能分析

1. 首先需要使用【慢查询日志】功能，去获取所有查询时间比较长的SQL语句

2. 其次【查看执行计划】查看有问题的SQL的执行计划 explain

3. 最后可以使用【show profifile[s]】 查看有问题的SQL的性能使用情况 

[一条SQL语句执行得很慢的原因有哪些？---不看后悔系列](https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247485185&idx=1&sn=66ef08b4ab6af5757792223a83fc0d45&chksm=cea248caf9d5c1dc72ec8a281ec16aa3ec3e8066dbb252e27362438a26c33fbe842b0e0adf47&token=79317275&lang=zh_CN%23rd)

1. sql语句写的太不好
2. 索引失效或者没加索引
3. 查询语句中包含了太多的join

一个 SQL 执行的很慢，我们要分两种情况讨论：

1、大多数情况下很正常，偶尔很慢，则有如下原因

(1)、数据库在刷新脏页，例如 redo log 写满了需要同步到磁盘。

(2)、执行的时候，遇到锁，如表锁、行锁。

2、这条 SQL 语句一直执行的很慢，则有如下原因。

(1)、没有用上索引：例如该字段没有索引；由于对字段进行运算、函数操作导致无法用索引。

(2)、数据库选错了索引。主要是因为基数判断错误，通过analyze table重新分析。

### 11 MVCC

推荐阅读：[MySQL-InnoDB-MVCC多版本并发控制](https://segmentfault.com/a/1190000012650596)

​	MVCC多版本并发控制（Multiversion Concurrency Control），多版本控制: 指的是一种提高并发的技术。**最早的数据库系统，只有读读之间可以并发**，读写，写读，写写都要阻塞。**引入多版本之后，只有写写之间相互阻塞**，其他三种操作都可以并行，这样大幅度提高了InnoDB的并发度。

​	**每一个写操作都会创建一个新版本的数据**，读操作会**从有限多个版本的数据中挑选一个最合适的结果**直接返回；在这时，**读写操作之间的冲突就不再需要被关注**，而**管理和快速挑选数据的版本就成了 MVCC 需要解决的主要问题**。

**<font color='blue'>MVCC 在mysql 中的实现依赖的是 undo log 与 read view</font>** 

 	各数据库中MVCC实现并不统一，**MVCC只在 READ COMMITTED 和 REPEATABLE READ 两个隔离级别下工作**，其他两个隔离级别和MVCC不兼容, 因为 **READ UNCOMMITTED 总是读取最新的数据行, 而不是符合当前事务版本的数据行。**而 **SERIALIZABLE 则会对所有读取的行都加锁**。

​	对于**使用InnoDB存储引擎的表**来说，它的**聚簇索引记录中都包含两个必要的隐藏列**：(**<font color='red'>trx_id事务ID、roll_pointer上个版本指针</font>,其实还有一个row_id的隐藏列但这里用不着**); 
<font color='red'>每次对记录进行改动，都会把对应的事务id赋值给trx_id隐藏列，也会把旧的版本写入到undo日志中</font>；

​	所以在并发情况下，一个记录可能存在多个版本，通过roll_pointer形成一个版本链。**MVCC的核心任务**就是：**判断一下版本链中的哪个版本是当前事务可见的**。这就有了**<font color='red'>ReadView</font>**的概念，这个**ReadView中主要包含当前系统中还有哪些活跃的读写事务**，把它们的事务id放到一个列表中，我们把**这个列表命名为为m_ids**；根据ReadView的**活跃事务ID列表和版本链事务ID进行比较找出可见的事务ID最大的版本**：

1、**如果版本的trx_id属性值小于m_ids列表中最小的事务id**，表明生成该版本的事务在生成ReadView前已经提交，所以**该版本可以被当前事务访问**。<font color='red'>//这里是遍历已有版本，判断是否能被活跃的读写事务访问，这些事务都被记录在m_ids中，这里的版本是指版本链中记录的版本</font>
2、**如果版本的trx_id属性值大于m_ids列表中最大的事务id**，表明生成该版本的事务在生成ReadView后才生成，所以该版本不可以被当前事务访问。
3、**被访问版本的trx_id属性值在m_ids列表中最大的事务id和最小事务id之间**，那就需要判断一下trx_id属性值是不是在m_ids列表中，**如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问<font color='red'>(可以理解为事务的隔离性吧，正在执行的事务不能被其他事务访问)</font>**；如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问。

MVCC只在读已提交和可重复读这两个隔离机制下运行。这两个隔离机制下MVCC实现方式的区别就在于：**读已提交是每次读取数据前都生成一个ReadView**；而**可重复读，是在第一次读取数据时生成一个ReadView，后序的重复查询就不再生产ReadView了**。

小结：
	**多版本并发控制指的就是在使用READ COMMITTD、REPEATABLE READ这两种隔离级别的事务在执行普通的SEELCT操作时访问记录的版本链的过程**，这样子可以使不同事务的读-写、写-读操作并发执行，从而提升系统性能。READ COMMITTD、REPEATABLE READ这两个隔离级别的一个很大不同就是生成ReadView的时机不同，READ COMMITTD在每一次进行普通SELECT操作前都会生成一个ReadView，而REPEATABLE READ只在第一次进行普通SELECT操作前生成一个ReadView，之后的查询操作都重复这个ReadView就好了。

#### 总结

1. 一般我们认为MVCC有下面几个特点：
   - 每行数据都存在一个版本，每次数据更新时都更新该版本
   - 修改时Copy出当前版本, 然后随意修改，各个事务之间无干扰
   - 保存时比较版本号，如果成功(commit)，则覆盖原记录, 失败则放弃copy(rollback)
   - 就是每行都有版本号，保存时根据版本号决定是否成功，**听起来含有乐观锁的味道, 因为这看起来正是，在提交的时候才能知道到底能否提交成功**
2. 而InnoDB实现MVCC的方式是:
   - 事务以排他锁的形式修改原始数据
   - 把修改前的数据存放于undo log，通过回滚指针与主数据关联
   - 修改成功（commit）啥都不做，失败则恢复undo log中的数据（rollback）
3. **二者最本质的区别是**: 当修改数据时是否要`排他锁定`，如果锁定了还算不算是MVCC？

- Innodb的实现真算不上MVCC, 因为并没有实现核心的多版本共存, `undo log` 中的内容只是串行化的结果, 记录了多个事务的过程, 不属于多版本共存。但理想的MVCC是难以实现的, 当事务仅修改一行记录使用理想的MVCC模式是没有问题的, 可以通过比较版本号进行回滚, 但当事务影响到多行数据时, 理想的MVCC就无能为力了。
- 比如, 如果事务A执行理想的MVCC, 修改Row1成功, 而修改Row2失败, 此时需要回滚Row1, 但因为Row1没有被锁定, 其数据可能又被事务B所修改, 如果此时回滚Row1的内容，则会破坏事务B的修改结果，导致事务B违反ACID。 这也正是所谓的 `第一类更新丢失` 的情况。
- 也正是因为**InnoDB使用的MVCC中结合了排他锁, 不是纯的MVCC,** 所以第一类更新丢失是不会出现了, 一般说更新丢失都是指第二类丢失更新。

### 12 explain平时怎么用？你平时优先观察哪些点？

explain出来的信息有10列，分别是 

```mysql
id、select_type、table、type、possible_keys、key、key_len、ref、rows、Extra
```

用于查询sql语句的使用情况...

优先观察的话，答索引相关，再说个有没有可能是extra里用到了临时表，文件排序啥的...

### 13 MySQL是如何执行一条SQL的

####  1 一条SQL查询语句是如何执行的？

![image-20210122150609712](https://zhipic.oss-cn-beijing.aliyuncs.com/20210122150611.png)

**「MySQL内部可以分为服务层和存储引擎层两部分：」**

**「服务层包括连接器、查询缓存、分析器、优化器、执行器等」**，涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。

**存储引擎层负责数据的存储和提取。**其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。现在最常用的存储引擎是InnoDB，它从MySQL 5.5.5版本开始成为了默认的存储引擎。

**「Server层按顺序执行sql的步骤为：」**

客户端请求->连接器（验证用户身份，给予权限） -> 查询缓存（存在缓存则直接返回，不存在则执行后续操作）->分析器（对SQL进行词法分析和语法分析操作） -> 优化器（主要对执行的sql优化选择最优的执行方案方法） -> 执行器（执行时会先看用户是否有执行权限，有才去使用这个引擎提供的接口）->去引擎层获取数据返回（如果开启查询缓存则会缓存查询结果）

**「简单概括」**：

- **「连接器」**：管理连接、权限验证；

- **「查询缓存」**：命中缓存则直接返回结果；大多数情况下建议不要使用查询缓存，因为查询缓存往往弊大于利。查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。适用于读多写少的场景，比如查往年记录等。**MySQL 8.0 版本直接将查询缓存的整块功能删掉了**，也就是说 8.0 开始彻底没有这个功能了。

- **「分析器」**：对SQL进行词法分析、语法分析；（判断查询的SQL字段是否存在也是在这步）

  - 分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL **需要识别出里面的字符串分别是什么，代表什么**。MySQL **从你输入的"select"这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”**

  - 然后做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。如下代码

  - ```
    mysql> elect * from t where ID=1;
    
    ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'elect * from t where ID=1' at line 1
    ```

- **「优化器」**：执行计划生成、选择索引；

- **「执行器」**：操作引擎、返回结果；

- **「存储引擎」**：存储数据、提供读写接口。

#### 2 一条SQL更新语句是如何执行的？

```mysql
mysql> update T set c=c+1 where ID=2;
```

首先，可以确定的说，查询语句的那一套流程，更新语句也是同样会走一遍。

你执行语句前要先连接数据库，这是连接器的工作。前面我们说过，在一个表上有更新的时候，跟这个表有关的查

询缓存会失效，所以这条语句就会把表 T 上所有缓存结果都清空。这也就是我们一般不建议使用查询缓存的原

因。接下来，分析器会通过词法和语法解析知道这是一条更新语句。优化器决定要使用 ID 这个索引。然后，执行

器负责具体执行，找到这一行，然后更新。与查询流程不一样的是，更新流程还涉及两个重要的日志模块，它们正

是我们今天要讨论的主角：redo log（重做日志）和 binlog（归档日志）。

**执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程**。

1、执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页

本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。

2、执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引

擎接口写入这行新数据。

3、引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状

态。然后告知执行器执行完成了，随时可以提交事务。

4、执行器生成这个操作的 binlog，并把 binlog 写入磁盘。

5、执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。

![image-20210122150719541](https://zhipic.oss-cn-beijing.aliyuncs.com/20210122150720.png)

**redo log 的写入拆成了两个步骤：prepare 和 commit，这就是"两阶段提交"。**

根据前面的主从复制可知，binlog用于主从库之间信息的同步以及机器备份的吧，而redo log则是用于当前库的数据恢复。

• **先写 redo log 直接提交，然后写 binlog**，假设写完 redo log 后，机器挂了，binlog 日志没有被写入，那么机器重启后，**这台机器会通过 redo log 恢复数据**，但是这个时候 binlog 并没有记录该数据，后续进行**机器备份**的时候，就会丢失这一条数据，同时**主从同步**也会丢失这一条数据。

• **先写 binlog，然后写 redo log**，假设写完了 binlog，机器异常重启了，由于没有 redo log，**本机是无法恢复**这一条记录的，但是 binlog 又有记录，那么和上面同样的道理，就会产生**数据不一致的**情况。

如果采用 redo log 两阶段提交的方式就不一样了，写完 binlog 后，然后再提交 redo log 就会防止出现上述的问题，从而保证了数据的一致性。那么问题来了，有没有一个极端的情况呢？

**假设 redo log 处于预提交状态，binglog 也已经写完了，这个时候发生了异常重启会怎么样呢**？ 这个就要依赖于 MySQL 的处理机制了，MySQL 的处理过程如下：

• 判断 redo log 是否完整，如果判断是完整的，也就是已经有了 commit 标识，就立即提交。

• 如果 redo log 只是预提交但不是 commit 状态，这个时候就会去判断 binlog 是否完整，如果完整就提交 redo log, 不完整就回滚事务。

redo log 用于保证 crash-safe 能力。**innodb_flush_log_at_trx_commit** 这个参数设置成 1 的时候，**表示每次事务的 redo log 都直接持久化到磁盘**。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。

**sync_binlog** 这个参数设置成 1 的时候，**表示每次事务的 binlog 都持久化到磁盘**。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。

**两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案**，即使你不做数据库内核开发，日常开发中也有可能会用到。

#### 总结

- MySQL 主要分为 Server 层和引擎层，Server 层主要包括连接器、查询缓存、分析器、优化器、执行器，同时还有一个日志模块（binlog），这个日志模块所有执行引擎都可以共用,redolog 只有 InnoDB 有。
- 引擎层是插件式的，目前主要包括，MyISAM,InnoDB,Memory 等。
- SQL 等执行过程分为两类，一类对于查询等过程如下：权限校验---》查询缓存---》分析器---》优化器---》权限校验---》执行器---》引擎
- 对于更新等语句执行流程如下：分析器----》权限校验----》执行器---》引擎---redo log prepare---》binlog---》redo log commit

